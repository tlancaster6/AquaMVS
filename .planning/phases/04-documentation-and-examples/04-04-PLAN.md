---
phase: 04-documentation-and-examples
plan: 04
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - docs/tutorial/index.rst
  - docs/tutorial/notebook.ipynb
  - docs/cli_guide.md
autonomous: true

must_haves:
  truths:
    - "Jupyter notebook demonstrates complete reconstruction workflow from config to mesh"
    - "CLI guide demonstrates equivalent workflow using aquamvs commands"
    - "Both formats show intermediate visualizations (depth maps, point clouds, mesh)"
  artifacts:
    - path: "docs/tutorial/notebook.ipynb"
      provides: "End-to-end reconstruction tutorial using Python API"
      contains: "Pipeline"
    - path: "docs/tutorial/index.rst"
      provides: "Tutorial landing page linking notebook and CLI guide"
    - path: "docs/cli_guide.md"
      provides: "CLI-focused reconstruction workflow guide"
      contains: "aquamvs run"
  key_links:
    - from: "docs/tutorial/notebook.ipynb"
      to: "src/aquamvs/pipeline/runner.py"
      via: "imports Pipeline class"
      pattern: "from aquamvs import Pipeline"
    - from: "docs/cli_guide.md"
      to: "src/aquamvs/cli.py"
      via: "documents CLI commands"
      pattern: "aquamvs"
---

<objective>
Create end-to-end tutorial in Jupyter notebook format (Python API) and CLI guide (markdown).

Purpose: Per user decision, dual format tutorials serve different user types. Jupyter notebook focuses on Pipeline class and programmatic API. Markdown guide focuses on `aquamvs run` CLI workflow. Both show intermediate visualizations: sparse match overlays, depth maps, consistency maps, fused point cloud, and final mesh.

Output: Jupyter notebook tutorial, CLI guide markdown, tutorial index page.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-documentation-and-examples/04-01-SUMMARY.md
@src/aquamvs/__init__.py
@src/aquamvs/pipeline/runner.py
@src/aquamvs/cli.py
@CLAUDE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Jupyter notebook tutorial</name>
  <files>docs/tutorial/index.rst, docs/tutorial/notebook.ipynb</files>
  <action>
1. Create `docs/tutorial/index.rst`:
   ```rst
   Tutorials
   =========

   .. toctree::
      :maxdepth: 2

      notebook

   See also the :doc:`CLI Guide </cli_guide>` for command-line workflow.
   ```

   Note: For the notebook to render in Sphinx, add `"nbsphinx"` extension to docs/conf.py (or reference it as a downloadable file). Since nbsphinx requires pandoc which complicates CI, instead create `docs/tutorial/notebook.rst` that provides a rendered summary with a download link to the .ipynb:
   ```rst
   End-to-End Reconstruction Tutorial
   ===================================

   This tutorial walks through a complete reconstruction from synchronized
   camera images to a 3D surface mesh using the Python API.

   :download:`Download Jupyter Notebook <notebook.ipynb>`

   [Rendered content below as RST, mirroring notebook cells]
   ```

2. Create `docs/tutorial/notebook.ipynb` as a Jupyter notebook with these cells:

   **Cell 1** (markdown): Title and introduction. What we'll build: take synchronized multi-camera images, run reconstruction, produce a 3D mesh. Mentions example dataset download.

   **Cell 2** (markdown): Prerequisites — install AquaMVS, download example dataset.

   **Cell 3** (code): Import and setup
   ```python
   from pathlib import Path
   from aquamvs import Pipeline, PipelineConfig

   # Point to example dataset (adjust path as needed)
   DATA_DIR = Path("example_data")
   CONFIG_PATH = DATA_DIR / "config.yaml"
   ```

   **Cell 4** (markdown): Section — "1. Load and Inspect Configuration"

   **Cell 5** (code): Load config and show key parameters
   ```python
   config = PipelineConfig.from_yaml(CONFIG_PATH)
   print(f"Cameras: {list(config.cameras.keys())}")
   print(f"Output: {config.output_dir}")
   print(f"Matcher: {config.sparse_matching.matcher_type}")
   print(f"Pipeline mode: {config.reconstruction.pipeline_mode}")
   ```

   **Cell 6** (markdown): Section — "2. Run the Pipeline"

   **Cell 7** (code): Run pipeline
   ```python
   pipeline = Pipeline(config)
   pipeline.run()
   ```

   **Cell 8** (markdown): Section — "3. Examine Intermediate Results". Explain that the pipeline saves depth maps, consistency maps, and point clouds to the output directory.

   **Cell 9** (code): Load and display a depth map
   ```python
   import numpy as np
   import matplotlib.pyplot as plt

   output = Path(config.output_dir) / "frame_000000"
   # Load a depth map (pick first camera)
   cam = list(config.cameras.keys())[0]
   depth = np.load(output / f"{cam}_depth.npz")["depth"]

   plt.figure(figsize=(10, 6))
   plt.imshow(depth, cmap="viridis")
   plt.colorbar(label="Depth (m)")
   plt.title(f"Depth Map — {cam}")
   plt.show()
   ```

   **Cell 10** (code): Load and display consistency map
   ```python
   consistency = np.load(output / f"{cam}_consistency.npz")["consistency"]
   plt.figure(figsize=(10, 6))
   plt.imshow(consistency, cmap="viridis")
   plt.colorbar(label="Consistent views")
   plt.title(f"Consistency Map — {cam}")
   plt.show()
   ```

   **Cell 11** (markdown): Section — "4. Visualize the Fused Point Cloud"

   **Cell 12** (code): Load fused point cloud
   ```python
   import open3d as o3d

   pcd = o3d.io.read_point_cloud(str(output / "fused.ply"))
   print(f"Points: {len(pcd.points)}")
   # Note: o3d.visualization.draw_geometries requires a display
   # In Jupyter, use the Open3D Jupyter visualizer or save a screenshot
   ```

   **Cell 13** (markdown): Section — "5. Surface Reconstruction and Export"

   **Cell 14** (code): Show mesh output
   ```python
   mesh = o3d.io.read_triangle_mesh(str(output / "surface.ply"))
   print(f"Vertices: {len(mesh.vertices)}")
   print(f"Triangles: {len(mesh.triangles)}")
   ```

   **Cell 15** (code): Export to OBJ
   ```python
   from aquamvs import export_mesh

   export_mesh(str(output / "surface.ply"), str(output / "surface.obj"))
   print("Exported to OBJ format")
   ```

   **Cell 16** (markdown): Section — "Next Steps". Links to theory docs, API reference, CLI guide.

   Important: The notebook is designed to be runnable with the example dataset but also readable as documentation. All cells should have clear outputs or comments describing what to expect. Include `# Expected output: ...` comments for cells that depend on specific data.

   Set notebook metadata kernel to python3.
  </action>
  <verify>Confirm notebook.ipynb is valid JSON (parse with python -c "import json; json.load(open('docs/tutorial/notebook.ipynb'))"). Confirm tutorial/index.rst references notebook correctly. Confirm docs/tutorial/notebook.rst exists with download link.</verify>
  <done>Jupyter notebook walks through complete reconstruction: config loading, pipeline execution, depth map visualization, point cloud inspection, mesh export</done>
</task>

<task type="auto">
  <name>Task 2: Write CLI guide</name>
  <files>docs/cli_guide.md</files>
  <action>
Create `docs/cli_guide.md` (markdown format, rendered by myst-parser from Plan 01) covering the CLI-focused reconstruction workflow.

Structure:

1. **Title**: "CLI Reconstruction Guide"

2. **Overview** (~5 lines): AquaMVS provides CLI commands for the complete reconstruction workflow. This guide walks through reconstruction using command-line tools.

3. **Step 1: Prepare Data** (~10 lines):
   - Download example dataset (link to Zenodo/GitHub Releases — use placeholder URL)
   - Directory structure expected: one video/image-directory per camera, calibration JSON

4. **Step 2: Generate Configuration** (~15 lines):
   ```bash
   aquamvs init --video-dir /path/to/videos \
                --pattern "^([a-z0-9]+)-" \
                --calibration calibration.json \
                --output-dir ./output
   ```
   - Explain the pattern regex (extracts camera name from filename)
   - Explain output: config.yaml with all cameras and default parameters

5. **Step 3: (Optional) Create ROI Masks** (~10 lines):
   ```bash
   aquamvs export-refs config.yaml --frame 0
   ```
   - Explains: exports undistorted reference images so you can draw ROI masks in image editor
   - Save masks as PNG in masks/ directory

6. **Step 4: Run Reconstruction** (~10 lines):
   ```bash
   aquamvs run config.yaml
   ```
   - Explain what happens: undistortion, feature matching, plane sweep stereo, depth fusion, surface reconstruction
   - Mention `--quiet` flag for non-interactive use

7. **Step 5: Examine Results** (~15 lines):
   - Output directory structure:
     ```
     output/
     ├── frame_000000/
     │   ├── {camera}_depth.npz
     │   ├── {camera}_consistency.npz
     │   ├── fused.ply
     │   └── surface.ply
     ```
   - View point cloud: `open3d.io.read_point_cloud("output/frame_000000/fused.ply")`

8. **Step 6: Export Mesh** (~10 lines):
   ```bash
   aquamvs export-mesh output/frame_000000/surface.ply --format obj
   aquamvs export-mesh output/frame_000000/surface.ply --format stl --simplify 10000
   ```

9. **Configuration Tips** (~15 lines):
   - Switching matcher type (lightglue vs roma)
   - Adjusting depth range
   - GPU vs CPU: `device: cuda` in config
   - Depth hypotheses count for quality vs speed tradeoff

10. **See Also**: Links to Python API tutorial, theory docs, API reference.
  </action>
  <verify>Confirm file exists and is valid markdown. Run `sphinx-build -W -b html docs/ docs/_build/html` — cli_guide.md renders via myst-parser without errors.</verify>
  <done>CLI guide covers complete workflow from data preparation through mesh export with configuration tips</done>
</task>

</tasks>

<verification>
1. `docs/tutorial/notebook.ipynb` is valid JSON and contains all expected cells
2. `docs/tutorial/index.rst` links to notebook
3. `docs/cli_guide.md` covers all CLI commands with examples
4. `sphinx-build -W -b html docs/ docs/_build/html` passes
5. Tutorial and CLI guide are complementary (API vs CLI focus)
</verification>

<success_criteria>
- Jupyter notebook demonstrates complete reconstruction workflow programmatically
- CLI guide demonstrates equivalent workflow via command line
- Both formats reference example dataset
- Both show what intermediate outputs look like
- Sphinx renders both formats correctly
</success_criteria>

<output>
After completion, create `.planning/phases/04-documentation-and-examples/04-04-SUMMARY.md`
</output>
