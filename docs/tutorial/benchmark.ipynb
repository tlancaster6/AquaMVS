{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000001",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/tlancaster6/AquaMVS/blob/main/docs/tutorial/benchmark.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Benchmarking Reconstruction Pathways\n",
    "\n",
    "This tutorial demonstrates how to benchmark AquaMVS reconstruction pathways,\n",
    "compare LightGlue and RoMa matching strategies, and visualize performance\n",
    "and quality metrics using the Python API.\n",
    "\n",
    "AquaMVS supports three reconstruction pathways:\n",
    "- **LG+SP sparse**: Fast sparse reconstruction using SuperPoint features\n",
    "- **LG+SP full**: Dense stereo seeded by LightGlue sparse matches\n",
    "- **RoMa full**: Dense stereo seeded by RoMa dense matches\n",
    "\n",
    "> **Why no RoMa sparse?** RoMa produces dense per-pixel warp fields, so\n",
    "> running it in sparse mode pays the same expensive matching cost but\n",
    "> discards most of the output to extract keypoints. Use LG+SP sparse for\n",
    "> efficient sparse reconstruction instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3a3ee3-587e-4d81-be81-de55dacc4905",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00000000000000000000000000000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "if importlib.util.find_spec(\"aquamvs\") is None:\n",
    "    subprocess.run(\n",
    "        [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"torch\",\n",
    "            \"torchvision\",\n",
    "            \"--index-url\",\n",
    "            \"https://download.pytorch.org/whl/cpu\",\n",
    "            \"-q\",\n",
    "        ],\n",
    "        check=True,\n",
    "    )\n",
    "    subprocess.run(\n",
    "        [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"git+https://github.com/cvg/LightGlue.git@edb2b83\",\n",
    "            \"git+https://github.com/tlancaster6/RoMaV2.git\",\n",
    "            \"aquamvs\",\n",
    "            \"-q\",\n",
    "        ],\n",
    "        check=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00000000000000000000000000000003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already present at aquamvs-example-dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "DATASET_URL = \"https://zenodo.org/records/18702024/files/aquamvs-example-dataset.zip\"\n",
    "DATASET_DIR = Path(\"aquamvs-example-dataset\")\n",
    "\n",
    "if not DATASET_DIR.exists():\n",
    "    print(\"Downloading example dataset...\")\n",
    "    urllib.request.urlretrieve(DATASET_URL, \"aquamvs-example-dataset.zip\")\n",
    "    with zipfile.ZipFile(\"aquamvs-example-dataset.zip\") as zf:\n",
    "        zf.extractall(DATASET_DIR)\n",
    "    os.remove(\"aquamvs-example-dataset.zip\")\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(f\"Dataset already present at {DATASET_DIR}\")\n",
    "\n",
    "# Change into the dataset directory so relative config paths resolve correctly\n",
    "os.chdir(DATASET_DIR)\n",
    "CONFIG_PATH = Path(\"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000004",
   "metadata": {},
   "source": [
    "## Running the Benchmark\n",
    "\n",
    "The `run_benchmark` function runs all three reconstruction pathways on a\n",
    "single frame and returns a `BenchmarkResult` with per-pathway timing,\n",
    "point count, and density metrics.\n",
    "\n",
    "| Pathway | Matcher | Mode | Description |\n",
    "|---------|---------|------|-------------|\n",
    "| RoMa full | RoMa | full | Dense stereo seeded by RoMa dense matches |\n",
    "| LG+SP full | LightGlue/SuperPoint | full | Dense stereo seeded by sparse matches |\n",
    "| LG+SP sparse | LightGlue/SuperPoint | sparse | Triangulation from sparse features only |\n",
    "\n",
    "> **Tip:** You can also run benchmarks from the command line:\n",
    "> `aquamvs benchmark config.yaml --frame 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00000000000000000000000000000007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tucke\\PycharmProjects\\AquaMVS\\src\\aquamvs\\projection\\refractive.py:57: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:39.)\n",
      "  self.K = self.K.to(device)\n",
      "Using cache found in C:\\Users\\tucke/.cache\\torch\\hub\\facebookresearch_dinov3_adc254450203739c8149213a7a69d8d905b4fcfa\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2026-02-21 10:04:56 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">romav2</span>.romav2 - romav<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">2:116</span> in __init__ - RoMa v2 initialized.                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2026-02-21 10:04:56\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;36mromav2\u001b[0m.romav2 - romav\u001b[1;92m2:116\u001b[0m in __init__ - RoMa v2 initialized.                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from aquamvs.benchmark.runner import run_benchmark\n",
    "\n",
    "benchmark_result = run_benchmark(config_path=CONFIG_PATH, frame=0)\n",
    "\n",
    "print(\n",
    "    f\"Benchmarked {len(benchmark_result.results)} pathways on frame {benchmark_result.frame}\"\n",
    ")\n",
    "print()\n",
    "\n",
    "for pw in benchmark_result.results:\n",
    "    total_s = pw.timing.total_time_ms / 1000.0\n",
    "    print(\n",
    "        f\"{pw.pathway_name:20s}: {total_s:.1f}s, \"\n",
    "        f\"{pw.point_count:,} points, \"\n",
    "        f\"density={pw.cloud_density:.0f} pts/m\\u00b2\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000008",
   "metadata": {},
   "source": [
    "## Visualizing Results\n",
    "\n",
    "The plots below compare the four pathways on two metrics:\n",
    "\n",
    "- **Total runtime** (left): How long each pathway takes end-to-end\n",
    "- **Point count** (right): How many 3D points each pathway produces after fusion\n",
    "\n",
    "Sparse pathways are typically faster but produce fewer points. Full (dense) pathways\n",
    "take longer but produce denser reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00000000000000000000000000000009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T11:10:24.943856Z",
     "iopub.status.busy": "2026-02-21T11:10:24.943856Z",
     "iopub.status.idle": "2026-02-21T11:10:25.169501Z",
     "shell.execute_reply": "2026-02-21T11:10:25.169501Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names = [pw.pathway_name for pw in benchmark_result.results]\n",
    "total_times_s = [pw.timing.total_time_ms / 1000.0 for pw in benchmark_result.results]\n",
    "point_counts = [pw.point_count for pw in benchmark_result.results]\n",
    "\n",
    "# Professional color palette: coral for RoMa, teal for LG+SP\n",
    "colors = [\"#e07b54\", \"#2e86ab\", \"#1a5276\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Total runtime\n",
    "axes[0].bar(names, total_times_s, color=colors)\n",
    "axes[0].set_title(\"Total Runtime per Pathway\", fontsize=13)\n",
    "axes[0].set_ylabel(\"Time (s)\")\n",
    "axes[0].set_xlabel(\"Pathway\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=15)\n",
    "for i, v in enumerate(total_times_s):\n",
    "    axes[0].text(i, v + 0.1, f\"{v:.1f}s\", ha=\"center\", fontsize=9)\n",
    "\n",
    "# Point count\n",
    "axes[1].bar(names, point_counts, color=colors)\n",
    "axes[1].set_title(\"Reconstructed Point Count per Pathway\", fontsize=13)\n",
    "axes[1].set_ylabel(\"Points\")\n",
    "axes[1].set_xlabel(\"Pathway\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=15)\n",
    "for i, v in enumerate(point_counts):\n",
    "    axes[1].text(i, v + max(point_counts) * 0.01, f\"{v:,}\", ha=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000010",
   "metadata": {},
   "source": [
    "## Stage Timing Breakdown\n",
    "\n",
    "The stacked bar chart below shows how each pathway spends its time across pipeline stages.\n",
    "This is useful for identifying bottlenecks and understanding where the pathways differ.\n",
    "\n",
    "Key stages:\n",
    "- **undistortion**: Lens distortion removal (same cost across all pathways)\n",
    "- **sparse_matching** / **dense_matching**: Feature extraction and matching\n",
    "- **depth_estimation**: Plane-sweep stereo (only in `full` mode)\n",
    "- **fusion**: Multi-view depth map merging (only in `full` mode)\n",
    "- **surface**: Surface reconstruction from the point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00000000000000000000000000000011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T11:10:25.169501Z",
     "iopub.status.busy": "2026-02-21T11:10:25.169501Z",
     "iopub.status.idle": "2026-02-21T11:10:25.346566Z",
     "shell.execute_reply": "2026-02-21T11:10:25.346566Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ordered stages and display labels\n",
    "STAGE_ORDER = [\n",
    "    (\"undistortion\", \"Undistortion\"),\n",
    "    (\"sparse_matching\", \"Sparse Matching\"),\n",
    "    (\"dense_matching\", \"Dense Matching\"),\n",
    "    (\"depth_estimation\", \"Depth Estimation\"),\n",
    "    (\"fusion\", \"Fusion\"),\n",
    "    (\"surface\", \"Surface\"),\n",
    "]\n",
    "STAGE_COLORS = [\"#4e8098\", \"#90c2e7\", \"#6baed6\", \"#e07b54\", \"#f4a261\", \"#a8dadc\"]\n",
    "\n",
    "pathway_names = [pw.pathway_name for pw in benchmark_result.results]\n",
    "x = np.arange(len(pathway_names))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bottoms = np.zeros(len(pathway_names))\n",
    "\n",
    "for (stage_key, stage_label), color in zip(STAGE_ORDER, STAGE_COLORS, strict=False):\n",
    "    stage_times = []\n",
    "    for pw in benchmark_result.results:\n",
    "        stage = pw.timing.stages.get(stage_key)\n",
    "        stage_times.append(stage.wall_time_ms / 1000.0 if stage is not None else 0.0)\n",
    "    ax.bar(x, stage_times, bottom=bottoms, color=color, label=stage_label)\n",
    "    bottoms += np.array(stage_times)\n",
    "\n",
    "ax.set_title(\"Stage Timing Breakdown per Pathway\", fontsize=13)\n",
    "ax.set_ylabel(\"Time (s)\")\n",
    "ax.set_xlabel(\"Pathway\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(pathway_names, rotation=15)\n",
    "ax.legend(loc=\"upper left\", fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000012",
   "metadata": {},
   "source": [
    "## Comparing Depth Maps\n",
    "\n",
    "Visual comparison of depth maps between pathways reveals differences in reconstruction\n",
    "coverage and quality. The benchmark saves outputs for each pathway to a separate\n",
    "subdirectory under `{output_dir}/benchmark/{pathway_safe_name}/`.\n",
    "\n",
    "The cell below attempts to load depth maps from two pathways (LG+SP full and RoMa full)\n",
    "for side-by-side comparison. Note that depth maps are only produced by `full` mode\n",
    "pathways; sparse mode produces point clouds from triangulation only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00000000000000000000000000000013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T11:10:25.352570Z",
     "iopub.status.busy": "2026-02-21T11:10:25.352570Z",
     "iopub.status.idle": "2026-02-21T11:10:25.522181Z",
     "shell.execute_reply": "2026-02-21T11:10:25.522181Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from aquamvs import PipelineConfig\n",
    "\n",
    "base_config = PipelineConfig.from_yaml(CONFIG_PATH)\n",
    "base_output = Path(base_config.output_dir)\n",
    "\n",
    "# Pathway output dirs use safe names (+ -> _, space -> _)\n",
    "pathway_dirs = {\n",
    "    \"LG+SP full\": base_output / \"benchmark\" / \"LG_SP_full\",\n",
    "    \"RoMa full\": base_output / \"benchmark\" / \"RoMa_full\",\n",
    "}\n",
    "\n",
    "# Use the first camera from the config\n",
    "cam = list(base_config.camera_input_map.keys())[0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "loaded_any = False\n",
    "\n",
    "for ax, (pathway_name, out_dir) in zip(axes, pathway_dirs.items(), strict=False):\n",
    "    depth_path = out_dir / \"frame_000000\" / \"depth_maps\" / f\"{cam}.npz\"\n",
    "    if depth_path.exists():\n",
    "        depth = np.load(depth_path)[\"depth\"]\n",
    "        im = ax.imshow(depth, cmap=\"viridis\")\n",
    "        plt.colorbar(im, ax=ax, label=\"Depth (m)\", shrink=0.8)\n",
    "        ax.set_title(f\"{pathway_name} \\u2014 {cam}\")\n",
    "        ax.axis(\"off\")\n",
    "        loaded_any = True\n",
    "    else:\n",
    "        ax.set_title(f\"{pathway_name}\")\n",
    "        ax.text(\n",
    "            0.5,\n",
    "            0.5,\n",
    "            f\"Depth map not found.\\nRun the benchmark first or check\\n{depth_path}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=9,\n",
    "        )\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "if loaded_any:\n",
    "    plt.suptitle(\"Depth Map Comparison (full-mode pathways)\", fontsize=13)\n",
    "else:\n",
    "    plt.suptitle(\"Run the benchmark above to generate depth maps\", fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tm4x7y3vryg",
   "metadata": {},
   "source": [
    "## Comparing 3D Reconstructions\n",
    "\n",
    "If `runtime.viz_enabled: true` is set in your config, each pathway renders\n",
    "static PNG snapshots of the fused point cloud. The cell below loads these\n",
    "pre-rendered images for a side-by-side comparison â€” no Open3D needed in\n",
    "the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dge4nq304k",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T11:10:25.525686Z",
     "iopub.status.busy": "2026-02-21T11:10:25.525686Z",
     "iopub.status.idle": "2026-02-21T11:10:25.794191Z",
     "shell.execute_reply": "2026-02-21T11:10:25.794191Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from aquamvs import PipelineConfig\n",
    "\n",
    "base_config = PipelineConfig.from_yaml(CONFIG_PATH)\n",
    "base_output = Path(base_config.output_dir)\n",
    "\n",
    "pathway_dirs = {\n",
    "    \"RoMa full\": base_output / \"benchmark\" / \"RoMa_full\",\n",
    "    \"LG+SP full\": base_output / \"benchmark\" / \"LG_SP_full\",\n",
    "    \"LG+SP sparse\": base_output / \"benchmark\" / \"LG_SP_sparse\",\n",
    "}\n",
    "\n",
    "viz_filename = \"fused_oblique.png\"\n",
    "images = {}\n",
    "for name, out_dir in pathway_dirs.items():\n",
    "    img_path = out_dir / \"frame_000000\" / \"viz\" / viz_filename\n",
    "    if img_path.exists():\n",
    "        images[name] = plt.imread(str(img_path))\n",
    "\n",
    "if images:\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(6 * n, 5))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    for ax, (name, img) in zip(axes, images.items(), strict=False):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(name, fontsize=12)\n",
    "        ax.axis(\"off\")\n",
    "    plt.suptitle(\"3D Reconstruction Comparison\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\n",
    "        \"No rendered PNGs found. To generate them, set `runtime.viz_enabled: true`\\n\"\n",
    "        \"in your config.yaml and re-run the benchmark.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000014",
   "metadata": {},
   "source": [
    "## Selecting a Pathway\n",
    "\n",
    "Use this table to guide your choice of reconstruction pathway:\n",
    "\n",
    "| Pathway | Speed | Point Density | Use Case |\n",
    "|---------|-------|---------------|----------|\n",
    "| LG+SP sparse | Fastest | Low | Quick preview, debugging, sparse structure |\n",
    "| LG+SP full | Moderate | High | General-purpose dense reconstruction |\n",
    "| RoMa full | Slowest | Highest | Maximum quality, challenging lighting/texture |\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- Start with **LG+SP sparse** to verify your dataset and configuration are correct.\n",
    "- Use **LG+SP full** for most production reconstructions.\n",
    "- Switch to **RoMa full** if you see sparse reconstruction failures or low point density\n",
    "  (often in textureless or highly reflective underwater scenes).\n",
    "\n",
    "To lock in a pathway for your workflow, set these fields in your `config.yaml`:\n",
    "\n",
    "```yaml\n",
    "matcher_type: lightglue  # or roma\n",
    "pipeline_mode: full       # or sparse\n",
    "```\n",
    "\n",
    "Or use the `--preset` flag when initializing: `aquamvs init --preset fast` applies\n",
    "speed-optimized parameter defaults across all pathways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000015",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **[CLI Guide](../cli_guide.md)**: Full reference for `aquamvs` command-line options\n",
    "- **[End-to-End Tutorial](notebook.ipynb)**: Step-by-step Python API walkthrough\n",
    "- **[Troubleshooting Guide](../troubleshooting.rst)**: Diagnose common reconstruction issues\n",
    "- **[API Reference](../api/index.rst)**: Documentation for `aquamvs.benchmark.runner`, `aquamvs.benchmark.report`, and all pipeline modules\n",
    "\n",
    "To save the benchmark report as a markdown file for later reference:\n",
    "\n",
    "```python\n",
    "from aquamvs.benchmark.report import save_markdown_report\n",
    "from pathlib import Path\n",
    "\n",
    "report_path = save_markdown_report(benchmark_result, output_dir=Path(\"./reports\"))\n",
    "print(f\"Report saved to {report_path}\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
