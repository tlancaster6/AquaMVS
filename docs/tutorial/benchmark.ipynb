{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000001",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/tlancaster6/AquaMVS/blob/main/docs/tutorial/benchmark.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Benchmarking Reconstruction Pathways\n",
    "\n",
    "This tutorial demonstrates how to benchmark AquaMVS reconstruction pathways,\n",
    "compare LightGlue and RoMa matching strategies, and visualize performance\n",
    "and quality metrics.\n",
    "\n",
    "AquaMVS supports four reconstruction pathways:\n",
    "- **LG+SP sparse**: Fast sparse reconstruction using SuperPoint features\n",
    "- **LG+SP full**: Dense stereo seeded by LightGlue sparse matches\n",
    "- **RoMa sparse**: Sparse reconstruction using dense RoMa correspondences\n",
    "- **RoMa full**: Dense stereo seeded by RoMa dense matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00000000000000000000000000000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "if importlib.util.find_spec(\"aquamvs\") is None:\n",
    "    subprocess.run(\n",
    "        [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"torch\",\n",
    "            \"torchvision\",\n",
    "            \"--index-url\",\n",
    "            \"https://download.pytorch.org/whl/cpu\",\n",
    "            \"-q\",\n",
    "        ],\n",
    "        check=True,\n",
    "    )\n",
    "    subprocess.run(\n",
    "        [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"git+https://github.com/cvg/LightGlue.git@edb2b83\",\n",
    "            \"git+https://github.com/tlancaster6/RoMaV2.git\",\n",
    "            \"aquamvs\",\n",
    "            \"-q\",\n",
    "        ],\n",
    "        check=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00000000000000000000000000000003",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport urllib.request\nimport zipfile\nfrom pathlib import Path\n\nDATASET_URL = \"https://zenodo.org/records/18702024/files/aquamvs-example-dataset.zip\"\nDATASET_DIR = Path(\"aquamvs-example-dataset\")\n\nif not DATASET_DIR.exists():\n    print(\"Downloading example dataset...\")\n    urllib.request.urlretrieve(DATASET_URL, \"aquamvs-example-dataset.zip\")\n    with zipfile.ZipFile(\"aquamvs-example-dataset.zip\") as zf:\n        zf.extractall(DATASET_DIR)\n    os.remove(\"aquamvs-example-dataset.zip\")\n    print(\"Done.\")\nelse:\n    print(f\"Dataset already present at {DATASET_DIR}\")\n\n# Change into the dataset directory so relative config paths resolve correctly\nos.chdir(DATASET_DIR)\nCONFIG_PATH = Path(\"config.yaml\")"
  },
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000004",
   "metadata": {},
   "source": [
    "## Running the Benchmark\n",
    "\n",
    "The `aquamvs benchmark` command runs all four reconstruction pathways on a\n",
    "single frame and produces a comparison table showing timing, point count,\n",
    "and point cloud density. Each pathway reads the same raw images but applies\n",
    "a different combination of feature matcher and pipeline mode:\n",
    "\n",
    "| Pathway | Matcher | Mode | Description |\n",
    "|---------|---------|------|-------------|\n",
    "| LG+SP sparse | LightGlue/SuperPoint | sparse | Triangulation from sparse features only |\n",
    "| LG+SP full | LightGlue/SuperPoint | full | Dense plane-sweep stereo seeded by sparse matches |\n",
    "| RoMa sparse | RoMa | sparse | Triangulation from dense RoMa correspondences |\n",
    "| RoMa full | RoMa | full | Dense plane-sweep stereo seeded by RoMa matches |\n",
    "\n",
    "The CLI is the primary interface for running benchmarks. The `--frame` flag\n",
    "selects which video frame to process (frame 0 is recommended for a quick comparison)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00000000000000000000000000000005",
   "metadata": {},
   "outputs": [],
   "source": "import subprocess\nimport sys\n\nresult = subprocess.run(\n    [\n        sys.executable,\n        \"-m\",\n        \"aquamvs\",\n        \"benchmark\",\n        str(CONFIG_PATH),\n        \"--frame\",\n        \"0\",\n    ],\n    capture_output=True,\n    text=True,\n)\nprint(result.stdout)\nif result.returncode != 0:\n    print(\"STDERR:\", result.stderr)"
  },
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000006",
   "metadata": {},
   "source": [
    "## Loading Results Programmatically\n",
    "\n",
    "For custom analysis and visualization, you can run the benchmark via the Python API\n",
    "and inspect the structured results directly. The `run_benchmark` function returns a\n",
    "`BenchmarkResult` containing per-pathway `PathwayResult` objects, each with timing\n",
    "information from the pipeline profiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00000000000000000000000000000007",
   "metadata": {},
   "outputs": [],
   "source": "from aquamvs.benchmark.runner import run_benchmark\n\nbenchmark_result = run_benchmark(config_path=CONFIG_PATH, frame=0)\n\nprint(\n    f\"Benchmarked {len(benchmark_result.results)} pathways on frame {benchmark_result.frame}\"\n)\nprint()\n\nfor pw in benchmark_result.results:\n    total_s = pw.timing.total_time_ms / 1000.0\n    print(\n        f\"{pw.pathway_name:20s}: {total_s:.1f}s, \"\n        f\"{pw.point_count:,} points, \"\n        f\"density={pw.cloud_density:.0f} pts/m\\u00b2\"\n    )"
  },
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000008",
   "metadata": {},
   "source": [
    "## Visualizing Results\n",
    "\n",
    "The plots below compare the four pathways on two metrics:\n",
    "\n",
    "- **Total runtime** (left): How long each pathway takes end-to-end\n",
    "- **Point count** (right): How many 3D points each pathway produces after fusion\n",
    "\n",
    "Sparse pathways are typically faster but produce fewer points. Full (dense) pathways\n",
    "take longer but produce denser reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00000000000000000000000000000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names = [pw.pathway_name for pw in benchmark_result.results]\n",
    "total_times_s = [pw.timing.total_time_ms / 1000.0 for pw in benchmark_result.results]\n",
    "point_counts = [pw.point_count for pw in benchmark_result.results]\n",
    "\n",
    "# Professional color palette: teal for LG+SP, coral for RoMa\n",
    "colors = [\"#2e86ab\", \"#1a5276\", \"#e07b54\", \"#922b21\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Total runtime\n",
    "axes[0].bar(names, total_times_s, color=colors)\n",
    "axes[0].set_title(\"Total Runtime per Pathway\", fontsize=13)\n",
    "axes[0].set_ylabel(\"Time (s)\")\n",
    "axes[0].set_xlabel(\"Pathway\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=15)\n",
    "for i, v in enumerate(total_times_s):\n",
    "    axes[0].text(i, v + 0.1, f\"{v:.1f}s\", ha=\"center\", fontsize=9)\n",
    "\n",
    "# Point count\n",
    "axes[1].bar(names, point_counts, color=colors)\n",
    "axes[1].set_title(\"Reconstructed Point Count per Pathway\", fontsize=13)\n",
    "axes[1].set_ylabel(\"Points\")\n",
    "axes[1].set_xlabel(\"Pathway\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=15)\n",
    "for i, v in enumerate(point_counts):\n",
    "    axes[1].text(i, v + max(point_counts) * 0.01, f\"{v:,}\", ha=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000010",
   "metadata": {},
   "source": [
    "## Stage Timing Breakdown\n",
    "\n",
    "The stacked bar chart below shows how each pathway spends its time across pipeline stages.\n",
    "This is useful for identifying bottlenecks and understanding where the pathways differ.\n",
    "\n",
    "Key stages:\n",
    "- **undistortion**: Lens distortion removal (same cost across all pathways)\n",
    "- **sparse_matching** / **dense_matching**: Feature extraction and matching\n",
    "- **depth_estimation**: Plane-sweep stereo (only in `full` mode)\n",
    "- **fusion**: Multi-view depth map merging (only in `full` mode)\n",
    "- **surface**: Surface reconstruction from the point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00000000000000000000000000000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ordered stages and display labels\n",
    "STAGE_ORDER = [\n",
    "    (\"undistortion\", \"Undistortion\"),\n",
    "    (\"sparse_matching\", \"Sparse Matching\"),\n",
    "    (\"dense_matching\", \"Dense Matching\"),\n",
    "    (\"depth_estimation\", \"Depth Estimation\"),\n",
    "    (\"fusion\", \"Fusion\"),\n",
    "    (\"surface\", \"Surface\"),\n",
    "]\n",
    "STAGE_COLORS = [\"#4e8098\", \"#90c2e7\", \"#6baed6\", \"#e07b54\", \"#f4a261\", \"#a8dadc\"]\n",
    "\n",
    "pathway_names = [pw.pathway_name for pw in benchmark_result.results]\n",
    "x = np.arange(len(pathway_names))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bottoms = np.zeros(len(pathway_names))\n",
    "\n",
    "for (stage_key, stage_label), color in zip(STAGE_ORDER, STAGE_COLORS, strict=False):\n",
    "    stage_times = []\n",
    "    for pw in benchmark_result.results:\n",
    "        stage = pw.timing.stages.get(stage_key)\n",
    "        stage_times.append(stage.wall_time_ms / 1000.0 if stage is not None else 0.0)\n",
    "    ax.bar(x, stage_times, bottom=bottoms, color=color, label=stage_label)\n",
    "    bottoms += np.array(stage_times)\n",
    "\n",
    "ax.set_title(\"Stage Timing Breakdown per Pathway\", fontsize=13)\n",
    "ax.set_ylabel(\"Time (s)\")\n",
    "ax.set_xlabel(\"Pathway\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(pathway_names, rotation=15)\n",
    "ax.legend(loc=\"upper left\", fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000012",
   "metadata": {},
   "source": [
    "## Comparing Depth Maps\n",
    "\n",
    "Visual comparison of depth maps between pathways reveals differences in reconstruction\n",
    "coverage and quality. The benchmark saves outputs for each pathway to a separate\n",
    "subdirectory under `{output_dir}/benchmark/{pathway_safe_name}/`.\n",
    "\n",
    "The cell below attempts to load depth maps from two pathways (LG+SP full and RoMa full)\n",
    "for side-by-side comparison. Note that depth maps are only produced by `full` mode\n",
    "pathways; sparse mode produces point clouds from triangulation only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00000000000000000000000000000013",
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom aquamvs import PipelineConfig\n\nbase_config = PipelineConfig.from_yaml(CONFIG_PATH)\nbase_output = Path(base_config.output_dir)\n\n# Pathway output dirs use safe names (+ -> _, space -> _)\npathway_dirs = {\n    \"LG+SP full\": base_output / \"benchmark\" / \"LG_SP_full\",\n    \"RoMa full\": base_output / \"benchmark\" / \"RoMa_full\",\n}\n\n# Use the first camera from the config\ncam = list(base_config.camera_input_map.keys())[0]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nloaded_any = False\n\nfor ax, (pathway_name, out_dir) in zip(axes, pathway_dirs.items(), strict=False):\n    depth_path = out_dir / \"frame_000000\" / \"depth_maps\" / f\"{cam}.npz\"\n    if depth_path.exists():\n        depth = np.load(depth_path)[\"depth\"]\n        im = ax.imshow(depth, cmap=\"viridis\")\n        plt.colorbar(im, ax=ax, label=\"Depth (m)\", shrink=0.8)\n        ax.set_title(f\"{pathway_name} \\u2014 {cam}\")\n        ax.axis(\"off\")\n        loaded_any = True\n    else:\n        ax.set_title(f\"{pathway_name}\")\n        ax.text(\n            0.5,\n            0.5,\n            f\"Depth map not found.\\nRun the benchmark first or check\\n{depth_path}\",\n            ha=\"center\",\n            va=\"center\",\n            transform=ax.transAxes,\n            fontsize=9,\n        )\n        ax.axis(\"off\")\n\nif loaded_any:\n    plt.suptitle(\"Depth Map Comparison (full-mode pathways)\", fontsize=13)\nelse:\n    plt.suptitle(\"Run the benchmark above to generate depth maps\", fontsize=11)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000014",
   "metadata": {},
   "source": [
    "## Selecting a Pathway\n",
    "\n",
    "Use this table to guide your choice of reconstruction pathway:\n",
    "\n",
    "| Pathway | Speed | Point Density | Use Case |\n",
    "|---------|-------|---------------|----------|\n",
    "| LG+SP sparse | Fastest | Low | Quick preview, debugging, sparse structure |\n",
    "| LG+SP full | Moderate | High | General-purpose dense reconstruction |\n",
    "| RoMa sparse | Moderate | Medium | Scenes with few texture features for sparse matching |\n",
    "| RoMa full | Slowest | Highest | Maximum quality, challenging lighting/texture |\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- Start with **LG+SP sparse** to verify your dataset and configuration are correct.\n",
    "- Use **LG+SP full** for most production reconstructions.\n",
    "- Switch to **RoMa full** if you see sparse reconstruction failures or low point density\n",
    "  (often in textureless or highly reflective underwater scenes).\n",
    "\n",
    "To lock in a pathway for your workflow, set these fields in your `config.yaml`:\n",
    "\n",
    "```yaml\n",
    "matcher_type: lightglue  # or roma\n",
    "pipeline_mode: full       # or sparse\n",
    "```\n",
    "\n",
    "Or use the `--preset` flag when initializing: `aquamvs init --preset fast` applies\n",
    "speed-optimized parameter defaults across all pathways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000000000000000000000000000015",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **[CLI Guide](../cli_guide.md)**: Full reference for `aquamvs` command-line options\n",
    "- **[End-to-End Tutorial](notebook.ipynb)**: Step-by-step Python API walkthrough\n",
    "- **[Troubleshooting Guide](../troubleshooting.rst)**: Diagnose common reconstruction issues\n",
    "- **[API Reference](../api/index.rst)**: Documentation for `aquamvs.benchmark.runner`, `aquamvs.benchmark.report`, and all pipeline modules\n",
    "\n",
    "To save the benchmark report as a markdown file for later reference:\n",
    "\n",
    "```python\n",
    "from aquamvs.benchmark.report import save_markdown_report\n",
    "from pathlib import Path\n",
    "\n",
    "report_path = save_markdown_report(benchmark_result, output_dir=Path(\"./reports\"))\n",
    "print(f\"Report saved to {report_path}\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
